{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8ztY17Mz-0e"
      },
      "source": [
        "# Neural Network with TensorFlow\n",
        "\n",
        "Langkah membuat Neural Network:\n",
        "\n",
        "- Siapkan Data -> Fitur\n",
        "  - Open/gather data\n",
        "  - Preprocessing\n",
        "  - Feature engineering\n",
        "- Buat arsitektur NN\n",
        "  - Sequential API\n",
        "  - Functional API\n",
        "- Compile (proses translate dari python ke bahasa mesin) model NN \n",
        "  - Tentukan Loss yang digunakan\n",
        "  - Tentukan Optimizer\n",
        "  - Tentukan metric yang ingin dimonitor\n",
        "  - Callback\n",
        "- Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHASxrT31rTI"
      },
      "source": [
        "# Modeling with Titanic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "o5IC3qJY1VhI",
        "outputId": "626b9430-822f-4412-dee7-e72992e2af6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Survived  Pclass  \\\n",
              "PassengerId                     \n",
              "1                   0       3   \n",
              "2                   1       1   \n",
              "3                   1       3   \n",
              "4                   1       1   \n",
              "5                   0       3   \n",
              "\n",
              "                                                          Name     Sex   Age  \\\n",
              "PassengerId                                                                    \n",
              "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
              "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
              "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
              "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
              "5                                     Allen, Mr. William Henry    male  35.0   \n",
              "\n",
              "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
              "PassengerId                                                          \n",
              "1                1      0         A/5 21171   7.2500   NaN        S  \n",
              "2                1      0          PC 17599  71.2833   C85        C  \n",
              "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "4                1      0            113803  53.1000  C123        S  \n",
              "5                0      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/afifai/pelatihan_machinelearning/master/data/train.csv\", index_col=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "synXhuv613Eo"
      },
      "outputs": [],
      "source": [
        "df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b58DK-Hm2BxB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=46)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8km9PJVX2juw"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_col = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "cat_col = ['Sex']\n",
        "\n",
        "num_pipeline = make_pipeline(SimpleImputer(strategy='median'),\n",
        "                             StandardScaler())\n",
        "\n",
        "cat_pipeline = make_pipeline(OneHotEncoder())\n",
        "\n",
        "data_pipeline = ColumnTransformer([\n",
        "    ('pipe_num', num_pipeline, num_col),\n",
        "    ('pipe_cat', cat_pipeline, cat_col)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsejk7w44FM6"
      },
      "outputs": [],
      "source": [
        "# ekstrak fiture\n",
        "X_train = data_pipeline.fit_transform(X_train)\n",
        "X_val = data_pipeline.transform(X_val)\n",
        "X_test = data_pipeline.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df1NwW095Rj2",
        "outputId": "34a4b4ef-f4f3-411c-d7d4-46843089c3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(681, 7)\n",
            "(76, 7)\n",
            "(134, 7)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrOnCU8-5oRs"
      },
      "source": [
        "## Buat Arsitektur NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-wjQ3aUoN8_"
      },
      "source": [
        "### Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14EzMIhA5Wng",
        "outputId": "c2f79f9b-a147-474e-d0ea-2b9ec5ad0fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 4s 10ms/step - loss: 0.9613 - accuracy: 0.3113 - val_loss: 0.7953 - val_accuracy: 0.4474\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.3216 - val_loss: 0.7661 - val_accuracy: 0.4737\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8849 - accuracy: 0.3289 - val_loss: 0.7399 - val_accuracy: 0.4737\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.8527 - accuracy: 0.3421 - val_loss: 0.7174 - val_accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.3612 - val_loss: 0.6970 - val_accuracy: 0.4737\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7990 - accuracy: 0.3862 - val_loss: 0.6785 - val_accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7770 - accuracy: 0.4537 - val_loss: 0.6625 - val_accuracy: 0.6053\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.4993 - val_loss: 0.6486 - val_accuracy: 0.6184\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.7405 - accuracy: 0.5242 - val_loss: 0.6361 - val_accuracy: 0.6711\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.5609 - val_loss: 0.6259 - val_accuracy: 0.7105\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.6021 - val_loss: 0.6171 - val_accuracy: 0.7500\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.6182 - val_loss: 0.6094 - val_accuracy: 0.7368\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6285 - val_loss: 0.6030 - val_accuracy: 0.7368\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6300 - val_loss: 0.5979 - val_accuracy: 0.7368\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.6344 - val_loss: 0.5941 - val_accuracy: 0.7368\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6373 - val_loss: 0.5904 - val_accuracy: 0.7237\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6476 - val_loss: 0.5869 - val_accuracy: 0.7237\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6490 - val_loss: 0.5835 - val_accuracy: 0.7237\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6476 - val_loss: 0.5801 - val_accuracy: 0.7105\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6476 - val_loss: 0.5770 - val_accuracy: 0.6974\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.6608 - val_loss: 0.5739 - val_accuracy: 0.6974\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6623 - val_loss: 0.5709 - val_accuracy: 0.6974\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6637 - val_loss: 0.5681 - val_accuracy: 0.6974\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6681 - val_loss: 0.5656 - val_accuracy: 0.6974\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.6681 - val_loss: 0.5631 - val_accuracy: 0.6842\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.6725 - val_loss: 0.5605 - val_accuracy: 0.6842\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.6725 - val_loss: 0.5579 - val_accuracy: 0.6842\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6799 - val_loss: 0.5553 - val_accuracy: 0.6842\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.6828 - val_loss: 0.5529 - val_accuracy: 0.6842\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6843 - val_loss: 0.5506 - val_accuracy: 0.6842\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6858 - val_loss: 0.5482 - val_accuracy: 0.6974\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6872 - val_loss: 0.5459 - val_accuracy: 0.6974\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.6887 - val_loss: 0.5432 - val_accuracy: 0.7105\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6902 - val_loss: 0.5415 - val_accuracy: 0.7105\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.6931 - val_loss: 0.5400 - val_accuracy: 0.6974\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.6975 - val_loss: 0.5379 - val_accuracy: 0.6974\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.6990 - val_loss: 0.5362 - val_accuracy: 0.6974\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.6990 - val_loss: 0.5340 - val_accuracy: 0.6974\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7004 - val_loss: 0.5321 - val_accuracy: 0.7105\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.6975 - val_loss: 0.5302 - val_accuracy: 0.7105\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7019 - val_loss: 0.5276 - val_accuracy: 0.7105\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7034 - val_loss: 0.5253 - val_accuracy: 0.7237\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7078 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7151 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7195 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7313 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7372 - val_loss: 0.5137 - val_accuracy: 0.7632\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7401 - val_loss: 0.5111 - val_accuracy: 0.7632\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7474 - val_loss: 0.5089 - val_accuracy: 0.7632\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7548 - val_loss: 0.5064 - val_accuracy: 0.7632\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7592 - val_loss: 0.5042 - val_accuracy: 0.7632\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7651 - val_loss: 0.5019 - val_accuracy: 0.7763\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7651 - val_loss: 0.4997 - val_accuracy: 0.7763\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7665 - val_loss: 0.4974 - val_accuracy: 0.7895\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7763\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7797 - val_loss: 0.4937 - val_accuracy: 0.7632\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7885 - val_loss: 0.4920 - val_accuracy: 0.7763\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7856 - val_loss: 0.4900 - val_accuracy: 0.7763\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7930 - val_loss: 0.4877 - val_accuracy: 0.7763\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7856 - val_loss: 0.4848 - val_accuracy: 0.7763\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7915 - val_loss: 0.4823 - val_accuracy: 0.7763\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7915 - val_loss: 0.4801 - val_accuracy: 0.7763\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7959 - val_loss: 0.4780 - val_accuracy: 0.7895\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7944 - val_loss: 0.4762 - val_accuracy: 0.7763\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7959 - val_loss: 0.4754 - val_accuracy: 0.7763\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7959 - val_loss: 0.4734 - val_accuracy: 0.7763\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7988 - val_loss: 0.4708 - val_accuracy: 0.7763\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8091 - val_loss: 0.4699 - val_accuracy: 0.7763\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.8164 - val_loss: 0.4693 - val_accuracy: 0.7763\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8179 - val_loss: 0.4677 - val_accuracy: 0.7763\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.8179 - val_loss: 0.4681 - val_accuracy: 0.7763\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8164 - val_loss: 0.4669 - val_accuracy: 0.7763\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8164 - val_loss: 0.4650 - val_accuracy: 0.7763\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8150 - val_loss: 0.4659 - val_accuracy: 0.7763\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.8164 - val_loss: 0.4653 - val_accuracy: 0.7763\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.8135 - val_loss: 0.4648 - val_accuracy: 0.7763\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8135 - val_loss: 0.4636 - val_accuracy: 0.7763\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.8135 - val_loss: 0.4659 - val_accuracy: 0.7763\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8120 - val_loss: 0.4640 - val_accuracy: 0.7763\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.8135 - val_loss: 0.4642 - val_accuracy: 0.7763\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8120 - val_loss: 0.4612 - val_accuracy: 0.7763\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8120 - val_loss: 0.4624 - val_accuracy: 0.7763\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8120 - val_loss: 0.4601 - val_accuracy: 0.7763\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8106 - val_loss: 0.4621 - val_accuracy: 0.7763\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8106 - val_loss: 0.4616 - val_accuracy: 0.7763\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8120 - val_loss: 0.4613 - val_accuracy: 0.7763\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8076 - val_loss: 0.4623 - val_accuracy: 0.7763\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8106 - val_loss: 0.4608 - val_accuracy: 0.7763\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8106 - val_loss: 0.4598 - val_accuracy: 0.7763\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8120 - val_loss: 0.4616 - val_accuracy: 0.7763\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8120 - val_loss: 0.4619 - val_accuracy: 0.7763\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8091 - val_loss: 0.4613 - val_accuracy: 0.7763\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.8106 - val_loss: 0.4605 - val_accuracy: 0.7763\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.8091 - val_loss: 0.4611 - val_accuracy: 0.7763\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8091 - val_loss: 0.4622 - val_accuracy: 0.7763\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.8091 - val_loss: 0.4624 - val_accuracy: 0.7763\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8076 - val_loss: 0.4616 - val_accuracy: 0.7763\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8076 - val_loss: 0.4618 - val_accuracy: 0.7763\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8091 - val_loss: 0.4620 - val_accuracy: 0.7763\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8091 - val_loss: 0.4600 - val_accuracy: 0.7763\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8091 - val_loss: 0.4619 - val_accuracy: 0.7763\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8076 - val_loss: 0.4595 - val_accuracy: 0.7763\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8091 - val_loss: 0.4604 - val_accuracy: 0.7763\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8091 - val_loss: 0.4586 - val_accuracy: 0.7763\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8076 - val_loss: 0.4580 - val_accuracy: 0.7763\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8091 - val_loss: 0.4585 - val_accuracy: 0.7763\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8091 - val_loss: 0.4585 - val_accuracy: 0.7763\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8091 - val_loss: 0.4573 - val_accuracy: 0.7763\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8091 - val_loss: 0.4553 - val_accuracy: 0.7763\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8106 - val_loss: 0.4523 - val_accuracy: 0.7763\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8091 - val_loss: 0.4497 - val_accuracy: 0.7763\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8091 - val_loss: 0.4483 - val_accuracy: 0.7763\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8106 - val_loss: 0.4454 - val_accuracy: 0.7763\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8106 - val_loss: 0.4434 - val_accuracy: 0.7763\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8106 - val_loss: 0.4417 - val_accuracy: 0.7763\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8106 - val_loss: 0.4412 - val_accuracy: 0.7763\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8106 - val_loss: 0.4411 - val_accuracy: 0.7763\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8120 - val_loss: 0.4413 - val_accuracy: 0.7763\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8120 - val_loss: 0.4399 - val_accuracy: 0.7895\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8120 - val_loss: 0.4401 - val_accuracy: 0.7895\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8106 - val_loss: 0.4393 - val_accuracy: 0.7895\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8120 - val_loss: 0.4376 - val_accuracy: 0.7895\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8150 - val_loss: 0.4375 - val_accuracy: 0.7895\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8164 - val_loss: 0.4375 - val_accuracy: 0.7895\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8164 - val_loss: 0.4370 - val_accuracy: 0.7895\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8179 - val_loss: 0.4350 - val_accuracy: 0.7895\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8179 - val_loss: 0.4349 - val_accuracy: 0.7895\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8179 - val_loss: 0.4358 - val_accuracy: 0.7895\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8209 - val_loss: 0.4369 - val_accuracy: 0.7895\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8194 - val_loss: 0.4371 - val_accuracy: 0.7895\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8194 - val_loss: 0.4378 - val_accuracy: 0.7895\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8179 - val_loss: 0.4375 - val_accuracy: 0.7763\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8179 - val_loss: 0.4373 - val_accuracy: 0.7763\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8194 - val_loss: 0.4369 - val_accuracy: 0.7895\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8194 - val_loss: 0.4374 - val_accuracy: 0.7895\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8194 - val_loss: 0.4365 - val_accuracy: 0.7895\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8223 - val_loss: 0.4365 - val_accuracy: 0.8026\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8209 - val_loss: 0.4364 - val_accuracy: 0.7895\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8209 - val_loss: 0.4363 - val_accuracy: 0.7895\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8223 - val_loss: 0.4350 - val_accuracy: 0.8026\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8223 - val_loss: 0.4361 - val_accuracy: 0.8026\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8209 - val_loss: 0.4365 - val_accuracy: 0.7895\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8209 - val_loss: 0.4361 - val_accuracy: 0.8026\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8209 - val_loss: 0.4365 - val_accuracy: 0.8026\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8194 - val_loss: 0.4368 - val_accuracy: 0.8026\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8194 - val_loss: 0.4372 - val_accuracy: 0.8026\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8194 - val_loss: 0.4363 - val_accuracy: 0.8026\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8194 - val_loss: 0.4365 - val_accuracy: 0.8026\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8209 - val_loss: 0.4346 - val_accuracy: 0.7895\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8223 - val_loss: 0.4360 - val_accuracy: 0.7895\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8209 - val_loss: 0.4357 - val_accuracy: 0.7895\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8209 - val_loss: 0.4361 - val_accuracy: 0.7895\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8223 - val_loss: 0.4372 - val_accuracy: 0.7895\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8223 - val_loss: 0.4375 - val_accuracy: 0.7895\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8223 - val_loss: 0.4370 - val_accuracy: 0.7895\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8223 - val_loss: 0.4348 - val_accuracy: 0.7895\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8223 - val_loss: 0.4344 - val_accuracy: 0.7895\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8223 - val_loss: 0.4353 - val_accuracy: 0.7895\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8223 - val_loss: 0.4357 - val_accuracy: 0.7895\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8223 - val_loss: 0.4348 - val_accuracy: 0.7895\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8209 - val_loss: 0.4341 - val_accuracy: 0.7895\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8223 - val_loss: 0.4343 - val_accuracy: 0.7895\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8223 - val_loss: 0.4349 - val_accuracy: 0.7895\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8223 - val_loss: 0.4348 - val_accuracy: 0.7895\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8223 - val_loss: 0.4333 - val_accuracy: 0.7895\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8223 - val_loss: 0.4347 - val_accuracy: 0.7895\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8223 - val_loss: 0.4315 - val_accuracy: 0.7895\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8223 - val_loss: 0.4319 - val_accuracy: 0.7895\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8238 - val_loss: 0.4331 - val_accuracy: 0.7895\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8238 - val_loss: 0.4324 - val_accuracy: 0.7895\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8238 - val_loss: 0.4323 - val_accuracy: 0.7895\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8223 - val_loss: 0.4339 - val_accuracy: 0.7895\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8223 - val_loss: 0.4335 - val_accuracy: 0.7895\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8223 - val_loss: 0.4328 - val_accuracy: 0.7895\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8223 - val_loss: 0.4331 - val_accuracy: 0.7895\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8223 - val_loss: 0.4346 - val_accuracy: 0.7895\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8223 - val_loss: 0.4342 - val_accuracy: 0.7895\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8223 - val_loss: 0.4327 - val_accuracy: 0.7895\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8223 - val_loss: 0.4311 - val_accuracy: 0.7895\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8223 - val_loss: 0.4319 - val_accuracy: 0.7895\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8223 - val_loss: 0.4316 - val_accuracy: 0.7895\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8223 - val_loss: 0.4315 - val_accuracy: 0.7895\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8209 - val_loss: 0.4293 - val_accuracy: 0.7895\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8238 - val_loss: 0.4298 - val_accuracy: 0.7895\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8223 - val_loss: 0.4309 - val_accuracy: 0.7895\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8223 - val_loss: 0.4320 - val_accuracy: 0.7895\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8223 - val_loss: 0.4320 - val_accuracy: 0.7895\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8209 - val_loss: 0.4306 - val_accuracy: 0.7895\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8209 - val_loss: 0.4322 - val_accuracy: 0.7895\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8223 - val_loss: 0.4327 - val_accuracy: 0.7895\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8209 - val_loss: 0.4337 - val_accuracy: 0.7895\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8223 - val_loss: 0.4336 - val_accuracy: 0.7895\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8223 - val_loss: 0.4310 - val_accuracy: 0.8026\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8209 - val_loss: 0.4324 - val_accuracy: 0.8026\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8209 - val_loss: 0.4315 - val_accuracy: 0.8026\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8209 - val_loss: 0.4301 - val_accuracy: 0.8026\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8223 - val_loss: 0.4306 - val_accuracy: 0.8026\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8223 - val_loss: 0.4301 - val_accuracy: 0.8026\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8209 - val_loss: 0.4311 - val_accuracy: 0.8026\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8209 - val_loss: 0.4309 - val_accuracy: 0.8026\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8209 - val_loss: 0.4302 - val_accuracy: 0.8026\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8209 - val_loss: 0.4307 - val_accuracy: 0.8026\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8223 - val_loss: 0.4313 - val_accuracy: 0.8026\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8209 - val_loss: 0.4304 - val_accuracy: 0.8026\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8223 - val_loss: 0.4304 - val_accuracy: 0.8026\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8209 - val_loss: 0.4277 - val_accuracy: 0.8026\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8223 - val_loss: 0.4310 - val_accuracy: 0.8026\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8238 - val_loss: 0.4302 - val_accuracy: 0.8026\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8223 - val_loss: 0.4296 - val_accuracy: 0.8158\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8223 - val_loss: 0.4298 - val_accuracy: 0.8158\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8223 - val_loss: 0.4285 - val_accuracy: 0.8158\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8209 - val_loss: 0.4301 - val_accuracy: 0.8158\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8223 - val_loss: 0.4301 - val_accuracy: 0.8158\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8194 - val_loss: 0.4287 - val_accuracy: 0.8158\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8209 - val_loss: 0.4300 - val_accuracy: 0.8158\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.4314 - val_accuracy: 0.8158\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8209 - val_loss: 0.4316 - val_accuracy: 0.8158\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8209 - val_loss: 0.4294 - val_accuracy: 0.8158\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8238 - val_loss: 0.4318 - val_accuracy: 0.8158\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8223 - val_loss: 0.4316 - val_accuracy: 0.8158\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8209 - val_loss: 0.4312 - val_accuracy: 0.8158\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8223 - val_loss: 0.4315 - val_accuracy: 0.8158\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8209 - val_loss: 0.4320 - val_accuracy: 0.8158\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8223 - val_loss: 0.4297 - val_accuracy: 0.8158\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8238 - val_loss: 0.4284 - val_accuracy: 0.8158\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8238 - val_loss: 0.4295 - val_accuracy: 0.8158\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8209 - val_loss: 0.4299 - val_accuracy: 0.8158\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8209 - val_loss: 0.4314 - val_accuracy: 0.8158\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8209 - val_loss: 0.4311 - val_accuracy: 0.8158\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8223 - val_loss: 0.4300 - val_accuracy: 0.8158\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8223 - val_loss: 0.4298 - val_accuracy: 0.8158\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8238 - val_loss: 0.4288 - val_accuracy: 0.8158\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8238 - val_loss: 0.4283 - val_accuracy: 0.8158\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8238 - val_loss: 0.4296 - val_accuracy: 0.8158\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8238 - val_loss: 0.4287 - val_accuracy: 0.8158\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8238 - val_loss: 0.4286 - val_accuracy: 0.8158\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8238 - val_loss: 0.4278 - val_accuracy: 0.8158\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8238 - val_loss: 0.4280 - val_accuracy: 0.8158\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8238 - val_loss: 0.4290 - val_accuracy: 0.8158\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8253 - val_loss: 0.4297 - val_accuracy: 0.8158\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8238 - val_loss: 0.4288 - val_accuracy: 0.8158\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8238 - val_loss: 0.4289 - val_accuracy: 0.8158\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8238 - val_loss: 0.4280 - val_accuracy: 0.8158\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8238 - val_loss: 0.4298 - val_accuracy: 0.8158\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8238 - val_loss: 0.4291 - val_accuracy: 0.8158\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8238 - val_loss: 0.4293 - val_accuracy: 0.8158\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8223 - val_loss: 0.4291 - val_accuracy: 0.8158\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8223 - val_loss: 0.4294 - val_accuracy: 0.8158\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8223 - val_loss: 0.4298 - val_accuracy: 0.8158\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8223 - val_loss: 0.4284 - val_accuracy: 0.8158\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8223 - val_loss: 0.4286 - val_accuracy: 0.8158\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8223 - val_loss: 0.4279 - val_accuracy: 0.8158\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8238 - val_loss: 0.4282 - val_accuracy: 0.8158\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8223 - val_loss: 0.4287 - val_accuracy: 0.8158\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8238 - val_loss: 0.4284 - val_accuracy: 0.8158\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8253 - val_loss: 0.4279 - val_accuracy: 0.8158\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8267 - val_loss: 0.4270 - val_accuracy: 0.8158\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8267 - val_loss: 0.4261 - val_accuracy: 0.8158\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8253 - val_loss: 0.4269 - val_accuracy: 0.8158\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8253 - val_loss: 0.4272 - val_accuracy: 0.8158\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8253 - val_loss: 0.4276 - val_accuracy: 0.8158\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8267 - val_loss: 0.4273 - val_accuracy: 0.8158\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8267 - val_loss: 0.4275 - val_accuracy: 0.8158\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8253 - val_loss: 0.4268 - val_accuracy: 0.8289\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8267 - val_loss: 0.4268 - val_accuracy: 0.8289\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8267 - val_loss: 0.4262 - val_accuracy: 0.8289\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8267 - val_loss: 0.4264 - val_accuracy: 0.8158\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8267 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8253 - val_loss: 0.4281 - val_accuracy: 0.8289\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8253 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8253 - val_loss: 0.4257 - val_accuracy: 0.8289\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8238 - val_loss: 0.4273 - val_accuracy: 0.8289\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8253 - val_loss: 0.4270 - val_accuracy: 0.8289\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8253 - val_loss: 0.4279 - val_accuracy: 0.8289\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8267 - val_loss: 0.4273 - val_accuracy: 0.8289\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.8289\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8267 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8267 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8238 - val_loss: 0.4239 - val_accuracy: 0.8289\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8238 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8253 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8267 - val_loss: 0.4260 - val_accuracy: 0.8289\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8253 - val_loss: 0.4262 - val_accuracy: 0.8289\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8267 - val_loss: 0.4268 - val_accuracy: 0.8289\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8267 - val_loss: 0.4284 - val_accuracy: 0.8289\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8267 - val_loss: 0.4267 - val_accuracy: 0.8289\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8267 - val_loss: 0.4271 - val_accuracy: 0.8289\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8267 - val_loss: 0.4253 - val_accuracy: 0.8289\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8267 - val_loss: 0.4270 - val_accuracy: 0.8289\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8253 - val_loss: 0.4279 - val_accuracy: 0.8289\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8282 - val_loss: 0.4261 - val_accuracy: 0.8289\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8282 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8267 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8282 - val_loss: 0.4257 - val_accuracy: 0.8289\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8282 - val_loss: 0.4254 - val_accuracy: 0.8289\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8282 - val_loss: 0.4261 - val_accuracy: 0.8289\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8267 - val_loss: 0.4271 - val_accuracy: 0.8289\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8267 - val_loss: 0.4279 - val_accuracy: 0.8289\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8282 - val_loss: 0.4268 - val_accuracy: 0.8289\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8267 - val_loss: 0.4274 - val_accuracy: 0.8289\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe3c00e2f50>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sequential API\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "dengan FUNCTIONAL API\n",
        "data_in = Input(shape=(7,1))\n",
        "hidden_1 = Dense(4, activation='relu')(data_in)\n",
        "out = Dense(1, activation='sigmoid')(hidden_1)\n",
        "\n",
        "model = Model(inputs=data_in, outputs=out)\n",
        "\"\"\"\n",
        "\n",
        "# buat arsitekturnya\n",
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_shape=(7,)))  # Hidden layer 1\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = 'adam',           # adam adalah optimizer paling modern\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "# train\n",
        "model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXt5S9jeCGLg",
        "outputId": "f72c4d29-3c33-425c-b01a-1273d33df62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8282 - val_loss: 0.4261 - val_accuracy: 0.8289\n",
            "Epoch 2/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8297 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 3/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8297 - val_loss: 0.4266 - val_accuracy: 0.8289\n",
            "Epoch 4/300\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.4081 - accuracy: 0.8297 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
            "Epoch 5/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8282 - val_loss: 0.4261 - val_accuracy: 0.8289\n",
            "Epoch 6/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8297 - val_loss: 0.4261 - val_accuracy: 0.8289\n",
            "Epoch 7/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8297 - val_loss: 0.4265 - val_accuracy: 0.8289\n",
            "Epoch 8/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8267 - val_loss: 0.4281 - val_accuracy: 0.8289\n",
            "Epoch 9/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8297 - val_loss: 0.4256 - val_accuracy: 0.8289\n",
            "Epoch 10/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8297 - val_loss: 0.4253 - val_accuracy: 0.8289\n",
            "Epoch 11/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 12/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8297 - val_loss: 0.4250 - val_accuracy: 0.8289\n",
            "Epoch 13/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8297 - val_loss: 0.4249 - val_accuracy: 0.8289\n",
            "Epoch 14/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8297 - val_loss: 0.4263 - val_accuracy: 0.8289\n",
            "Epoch 15/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4260 - val_accuracy: 0.8289\n",
            "Epoch 16/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8297 - val_loss: 0.4231 - val_accuracy: 0.8289\n",
            "Epoch 17/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 18/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 19/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 20/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8297 - val_loss: 0.4230 - val_accuracy: 0.8289\n",
            "Epoch 21/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8297 - val_loss: 0.4256 - val_accuracy: 0.8289\n",
            "Epoch 22/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4260 - val_accuracy: 0.8289\n",
            "Epoch 23/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4263 - val_accuracy: 0.8289\n",
            "Epoch 24/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 25/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 26/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 27/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 28/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4253 - val_accuracy: 0.8289\n",
            "Epoch 29/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8282 - val_loss: 0.4273 - val_accuracy: 0.8289\n",
            "Epoch 30/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8297 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 31/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 32/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4255 - val_accuracy: 0.8289\n",
            "Epoch 33/300\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4262 - val_accuracy: 0.8289\n",
            "Epoch 34/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8282 - val_loss: 0.4255 - val_accuracy: 0.8289\n",
            "Epoch 35/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8282 - val_loss: 0.4270 - val_accuracy: 0.8289\n",
            "Epoch 36/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8282 - val_loss: 0.4264 - val_accuracy: 0.8289\n",
            "Epoch 37/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8282 - val_loss: 0.4259 - val_accuracy: 0.8289\n",
            "Epoch 38/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8282 - val_loss: 0.4258 - val_accuracy: 0.8289\n",
            "Epoch 39/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8282 - val_loss: 0.4259 - val_accuracy: 0.8289\n",
            "Epoch 40/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8297 - val_loss: 0.4233 - val_accuracy: 0.8289\n",
            "Epoch 41/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8297 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 42/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 43/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4255 - val_accuracy: 0.8289\n",
            "Epoch 44/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8282 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 45/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8282 - val_loss: 0.4278 - val_accuracy: 0.8289\n",
            "Epoch 46/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8282 - val_loss: 0.4283 - val_accuracy: 0.8289\n",
            "Epoch 47/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8282 - val_loss: 0.4266 - val_accuracy: 0.8289\n",
            "Epoch 48/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8267 - val_loss: 0.4273 - val_accuracy: 0.8289\n",
            "Epoch 49/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8282 - val_loss: 0.4235 - val_accuracy: 0.8289\n",
            "Epoch 50/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 51/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 52/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8297 - val_loss: 0.4250 - val_accuracy: 0.8289\n",
            "Epoch 53/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8282 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 54/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8297 - val_loss: 0.4232 - val_accuracy: 0.8289\n",
            "Epoch 55/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8282 - val_loss: 0.4245 - val_accuracy: 0.8289\n",
            "Epoch 56/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4242 - val_accuracy: 0.8289\n",
            "Epoch 57/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8282 - val_loss: 0.4253 - val_accuracy: 0.8289\n",
            "Epoch 58/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8297 - val_loss: 0.4240 - val_accuracy: 0.8289\n",
            "Epoch 59/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8297 - val_loss: 0.4241 - val_accuracy: 0.8289\n",
            "Epoch 60/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8282 - val_loss: 0.4254 - val_accuracy: 0.8289\n",
            "Epoch 61/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8282 - val_loss: 0.4249 - val_accuracy: 0.8289\n",
            "Epoch 62/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8282 - val_loss: 0.4252 - val_accuracy: 0.8289\n",
            "Epoch 63/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4231 - val_accuracy: 0.8289\n",
            "Epoch 64/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 65/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4222 - val_accuracy: 0.8289\n",
            "Epoch 66/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4235 - val_accuracy: 0.8289\n",
            "Epoch 67/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 68/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 69/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8282 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 70/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8297 - val_loss: 0.4238 - val_accuracy: 0.8289\n",
            "Epoch 71/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8297 - val_loss: 0.4227 - val_accuracy: 0.8289\n",
            "Epoch 72/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4247 - val_accuracy: 0.8289\n",
            "Epoch 73/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4235 - val_accuracy: 0.8289\n",
            "Epoch 74/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 75/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8282 - val_loss: 0.4255 - val_accuracy: 0.8289\n",
            "Epoch 76/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 77/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8282 - val_loss: 0.4243 - val_accuracy: 0.8289\n",
            "Epoch 78/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8282 - val_loss: 0.4232 - val_accuracy: 0.8289\n",
            "Epoch 79/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4229 - val_accuracy: 0.8289\n",
            "Epoch 80/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8297 - val_loss: 0.4227 - val_accuracy: 0.8289\n",
            "Epoch 81/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4231 - val_accuracy: 0.8289\n",
            "Epoch 82/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4232 - val_accuracy: 0.8289\n",
            "Epoch 83/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8297 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 84/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4239 - val_accuracy: 0.8289\n",
            "Epoch 85/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4241 - val_accuracy: 0.8289\n",
            "Epoch 86/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 87/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8282 - val_loss: 0.4237 - val_accuracy: 0.8289\n",
            "Epoch 88/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8297 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 89/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4218 - val_accuracy: 0.8289\n",
            "Epoch 90/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4248 - val_accuracy: 0.8289\n",
            "Epoch 91/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4231 - val_accuracy: 0.8289\n",
            "Epoch 92/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8311 - val_loss: 0.4244 - val_accuracy: 0.8289\n",
            "Epoch 93/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8311 - val_loss: 0.4251 - val_accuracy: 0.8289\n",
            "Epoch 94/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8297 - val_loss: 0.4241 - val_accuracy: 0.8289\n",
            "Epoch 95/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8297 - val_loss: 0.4250 - val_accuracy: 0.8289\n",
            "Epoch 96/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8297 - val_loss: 0.4241 - val_accuracy: 0.8289\n",
            "Epoch 97/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8297 - val_loss: 0.4233 - val_accuracy: 0.8289\n",
            "Epoch 98/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4233 - val_accuracy: 0.8289\n",
            "Epoch 99/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4235 - val_accuracy: 0.8289\n",
            "Epoch 100/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4218 - val_accuracy: 0.8289\n",
            "Epoch 101/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8297 - val_loss: 0.4224 - val_accuracy: 0.8289\n",
            "Epoch 102/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4231 - val_accuracy: 0.8289\n",
            "Epoch 103/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8282 - val_loss: 0.4240 - val_accuracy: 0.8289\n",
            "Epoch 104/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8282 - val_loss: 0.4230 - val_accuracy: 0.8289\n",
            "Epoch 105/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8311 - val_loss: 0.4240 - val_accuracy: 0.8289\n",
            "Epoch 106/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8282 - val_loss: 0.4249 - val_accuracy: 0.8289\n",
            "Epoch 107/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.4245 - val_accuracy: 0.8289\n",
            "Epoch 108/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8282 - val_loss: 0.4239 - val_accuracy: 0.8289\n",
            "Epoch 109/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8311 - val_loss: 0.4225 - val_accuracy: 0.8289\n",
            "Epoch 110/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8311 - val_loss: 0.4226 - val_accuracy: 0.8289\n",
            "Epoch 111/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8297 - val_loss: 0.4215 - val_accuracy: 0.8289\n",
            "Epoch 112/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8311 - val_loss: 0.4222 - val_accuracy: 0.8289\n",
            "Epoch 113/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8282 - val_loss: 0.4206 - val_accuracy: 0.8289\n",
            "Epoch 114/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8297 - val_loss: 0.4225 - val_accuracy: 0.8289\n",
            "Epoch 115/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8297 - val_loss: 0.4229 - val_accuracy: 0.8289\n",
            "Epoch 116/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8297 - val_loss: 0.4223 - val_accuracy: 0.8289\n",
            "Epoch 117/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8282 - val_loss: 0.4232 - val_accuracy: 0.8289\n",
            "Epoch 118/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8311 - val_loss: 0.4219 - val_accuracy: 0.8289\n",
            "Epoch 119/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8297 - val_loss: 0.4207 - val_accuracy: 0.8289\n",
            "Epoch 120/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 0.4209 - val_accuracy: 0.8289\n",
            "Epoch 121/300\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8297 - val_loss: 0.4184 - val_accuracy: 0.8289\n",
            "Epoch 122/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8282 - val_loss: 0.4199 - val_accuracy: 0.8289\n",
            "Epoch 123/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 0.4183 - val_accuracy: 0.8289\n",
            "Epoch 124/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8282 - val_loss: 0.4186 - val_accuracy: 0.8289\n",
            "Epoch 125/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 126/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8282 - val_loss: 0.4178 - val_accuracy: 0.8289\n",
            "Epoch 127/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 128/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8282 - val_loss: 0.4176 - val_accuracy: 0.8289\n",
            "Epoch 129/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8282 - val_loss: 0.4186 - val_accuracy: 0.8289\n",
            "Epoch 130/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4204 - val_accuracy: 0.8289\n",
            "Epoch 131/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8297 - val_loss: 0.4208 - val_accuracy: 0.8289\n",
            "Epoch 132/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8297 - val_loss: 0.4202 - val_accuracy: 0.8289\n",
            "Epoch 133/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8297 - val_loss: 0.4189 - val_accuracy: 0.8289\n",
            "Epoch 134/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8297 - val_loss: 0.4206 - val_accuracy: 0.8289\n",
            "Epoch 135/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8297 - val_loss: 0.4196 - val_accuracy: 0.8289\n",
            "Epoch 136/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8297 - val_loss: 0.4191 - val_accuracy: 0.8289\n",
            "Epoch 137/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8297 - val_loss: 0.4191 - val_accuracy: 0.8289\n",
            "Epoch 138/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 139/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8297 - val_loss: 0.4192 - val_accuracy: 0.8289\n",
            "Epoch 140/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4177 - val_accuracy: 0.8289\n",
            "Epoch 141/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8282 - val_loss: 0.4181 - val_accuracy: 0.8289\n",
            "Epoch 142/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8267 - val_loss: 0.4195 - val_accuracy: 0.8289\n",
            "Epoch 143/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4178 - val_accuracy: 0.8289\n",
            "Epoch 144/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 145/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 146/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8297 - val_loss: 0.4195 - val_accuracy: 0.8289\n",
            "Epoch 147/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8297 - val_loss: 0.4180 - val_accuracy: 0.8289\n",
            "Epoch 148/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8297 - val_loss: 0.4180 - val_accuracy: 0.8289\n",
            "Epoch 149/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8297 - val_loss: 0.4196 - val_accuracy: 0.8289\n",
            "Epoch 150/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8282 - val_loss: 0.4209 - val_accuracy: 0.8289\n",
            "Epoch 151/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8282 - val_loss: 0.4201 - val_accuracy: 0.8289\n",
            "Epoch 152/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8282 - val_loss: 0.4199 - val_accuracy: 0.8289\n",
            "Epoch 153/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8282 - val_loss: 0.4201 - val_accuracy: 0.8289\n",
            "Epoch 154/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8282 - val_loss: 0.4199 - val_accuracy: 0.8289\n",
            "Epoch 155/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8267 - val_loss: 0.4204 - val_accuracy: 0.8289\n",
            "Epoch 156/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8297 - val_loss: 0.4185 - val_accuracy: 0.8289\n",
            "Epoch 157/300\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8297 - val_loss: 0.4184 - val_accuracy: 0.8289\n",
            "Epoch 158/300\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8297 - val_loss: 0.4183 - val_accuracy: 0.8289\n",
            "Epoch 159/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8297 - val_loss: 0.4183 - val_accuracy: 0.8289\n",
            "Epoch 160/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8297 - val_loss: 0.4188 - val_accuracy: 0.8289\n",
            "Epoch 161/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8282 - val_loss: 0.4195 - val_accuracy: 0.8289\n",
            "Epoch 162/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8297 - val_loss: 0.4176 - val_accuracy: 0.8289\n",
            "Epoch 163/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8297 - val_loss: 0.4186 - val_accuracy: 0.8289\n",
            "Epoch 164/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8297 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 165/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8297 - val_loss: 0.4184 - val_accuracy: 0.8289\n",
            "Epoch 166/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8282 - val_loss: 0.4202 - val_accuracy: 0.8289\n",
            "Epoch 167/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8282 - val_loss: 0.4200 - val_accuracy: 0.8289\n",
            "Epoch 168/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8282 - val_loss: 0.4191 - val_accuracy: 0.8289\n",
            "Epoch 169/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8297 - val_loss: 0.4178 - val_accuracy: 0.8289\n",
            "Epoch 170/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8297 - val_loss: 0.4175 - val_accuracy: 0.8289\n",
            "Epoch 171/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8297 - val_loss: 0.4181 - val_accuracy: 0.8289\n",
            "Epoch 172/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8282 - val_loss: 0.4194 - val_accuracy: 0.8289\n",
            "Epoch 173/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8282 - val_loss: 0.4183 - val_accuracy: 0.8289\n",
            "Epoch 174/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8282 - val_loss: 0.4173 - val_accuracy: 0.8289\n",
            "Epoch 175/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8297 - val_loss: 0.4153 - val_accuracy: 0.8289\n",
            "Epoch 176/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8297 - val_loss: 0.4172 - val_accuracy: 0.8289\n",
            "Epoch 177/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8297 - val_loss: 0.4157 - val_accuracy: 0.8289\n",
            "Epoch 178/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8297 - val_loss: 0.4180 - val_accuracy: 0.8289\n",
            "Epoch 179/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8297 - val_loss: 0.4164 - val_accuracy: 0.8289\n",
            "Epoch 180/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8297 - val_loss: 0.4159 - val_accuracy: 0.8289\n",
            "Epoch 181/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8297 - val_loss: 0.4173 - val_accuracy: 0.8289\n",
            "Epoch 182/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8297 - val_loss: 0.4156 - val_accuracy: 0.8289\n",
            "Epoch 183/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8297 - val_loss: 0.4175 - val_accuracy: 0.8289\n",
            "Epoch 184/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8282 - val_loss: 0.4177 - val_accuracy: 0.8289\n",
            "Epoch 185/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8297 - val_loss: 0.4179 - val_accuracy: 0.8289\n",
            "Epoch 186/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8282 - val_loss: 0.4182 - val_accuracy: 0.8289\n",
            "Epoch 187/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8297 - val_loss: 0.4167 - val_accuracy: 0.8289\n",
            "Epoch 188/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8297 - val_loss: 0.4146 - val_accuracy: 0.8289\n",
            "Epoch 189/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8311 - val_loss: 0.4149 - val_accuracy: 0.8289\n",
            "Epoch 190/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8311 - val_loss: 0.4154 - val_accuracy: 0.8289\n",
            "Epoch 191/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8311 - val_loss: 0.4163 - val_accuracy: 0.8289\n",
            "Epoch 192/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8297 - val_loss: 0.4159 - val_accuracy: 0.8289\n",
            "Epoch 193/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8297 - val_loss: 0.4133 - val_accuracy: 0.8289\n",
            "Epoch 194/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8297 - val_loss: 0.4120 - val_accuracy: 0.8289\n",
            "Epoch 195/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8297 - val_loss: 0.4146 - val_accuracy: 0.8289\n",
            "Epoch 196/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8297 - val_loss: 0.4145 - val_accuracy: 0.8289\n",
            "Epoch 197/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8297 - val_loss: 0.4164 - val_accuracy: 0.8289\n",
            "Epoch 198/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8282 - val_loss: 0.4145 - val_accuracy: 0.8289\n",
            "Epoch 199/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8297 - val_loss: 0.4149 - val_accuracy: 0.8289\n",
            "Epoch 200/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8282 - val_loss: 0.4160 - val_accuracy: 0.8289\n",
            "Epoch 201/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8282 - val_loss: 0.4173 - val_accuracy: 0.8289\n",
            "Epoch 202/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8282 - val_loss: 0.4150 - val_accuracy: 0.8289\n",
            "Epoch 203/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8297 - val_loss: 0.4154 - val_accuracy: 0.8289\n",
            "Epoch 204/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8297 - val_loss: 0.4141 - val_accuracy: 0.8289\n",
            "Epoch 205/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8297 - val_loss: 0.4123 - val_accuracy: 0.8289\n",
            "Epoch 206/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8311 - val_loss: 0.4144 - val_accuracy: 0.8289\n",
            "Epoch 207/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8297 - val_loss: 0.4149 - val_accuracy: 0.8289\n",
            "Epoch 208/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8282 - val_loss: 0.4166 - val_accuracy: 0.8289\n",
            "Epoch 209/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8297 - val_loss: 0.4157 - val_accuracy: 0.8289\n",
            "Epoch 210/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8282 - val_loss: 0.4164 - val_accuracy: 0.8289\n",
            "Epoch 211/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8282 - val_loss: 0.4169 - val_accuracy: 0.8289\n",
            "Epoch 212/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8282 - val_loss: 0.4145 - val_accuracy: 0.8289\n",
            "Epoch 213/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8297 - val_loss: 0.4136 - val_accuracy: 0.8289\n",
            "Epoch 214/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8311 - val_loss: 0.4117 - val_accuracy: 0.8289\n",
            "Epoch 215/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4145 - val_accuracy: 0.8289\n",
            "Epoch 216/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8297 - val_loss: 0.4168 - val_accuracy: 0.8289\n",
            "Epoch 217/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8282 - val_loss: 0.4187 - val_accuracy: 0.8289\n",
            "Epoch 218/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8282 - val_loss: 0.4162 - val_accuracy: 0.8289\n",
            "Epoch 219/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8297 - val_loss: 0.4152 - val_accuracy: 0.8289\n",
            "Epoch 220/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4152 - val_accuracy: 0.8289\n",
            "Epoch 221/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8297 - val_loss: 0.4150 - val_accuracy: 0.8289\n",
            "Epoch 222/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8311 - val_loss: 0.4170 - val_accuracy: 0.8289\n",
            "Epoch 223/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8297 - val_loss: 0.4177 - val_accuracy: 0.8289\n",
            "Epoch 224/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8297 - val_loss: 0.4171 - val_accuracy: 0.8289\n",
            "Epoch 225/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4169 - val_accuracy: 0.8289\n",
            "Epoch 226/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8311 - val_loss: 0.4170 - val_accuracy: 0.8289\n",
            "Epoch 227/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8311 - val_loss: 0.4159 - val_accuracy: 0.8289\n",
            "Epoch 228/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4160 - val_accuracy: 0.8158\n",
            "Epoch 229/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8311 - val_loss: 0.4197 - val_accuracy: 0.8289\n",
            "Epoch 230/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4170 - val_accuracy: 0.8158\n",
            "Epoch 231/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8311 - val_loss: 0.4169 - val_accuracy: 0.8158\n",
            "Epoch 232/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8311 - val_loss: 0.4170 - val_accuracy: 0.8289\n",
            "Epoch 233/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8311 - val_loss: 0.4155 - val_accuracy: 0.8158\n",
            "Epoch 234/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8311 - val_loss: 0.4160 - val_accuracy: 0.8289\n",
            "Epoch 235/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8311 - val_loss: 0.4159 - val_accuracy: 0.8158\n",
            "Epoch 236/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4151 - val_accuracy: 0.8289\n",
            "Epoch 237/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8311 - val_loss: 0.4158 - val_accuracy: 0.8158\n",
            "Epoch 238/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4148 - val_accuracy: 0.8158\n",
            "Epoch 239/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8311 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 240/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 241/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4181 - val_accuracy: 0.8158\n",
            "Epoch 242/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8311 - val_loss: 0.4169 - val_accuracy: 0.8158\n",
            "Epoch 243/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8311 - val_loss: 0.4167 - val_accuracy: 0.8289\n",
            "Epoch 244/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8311 - val_loss: 0.4157 - val_accuracy: 0.8158\n",
            "Epoch 245/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8311 - val_loss: 0.4156 - val_accuracy: 0.8158\n",
            "Epoch 246/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8326 - val_loss: 0.4158 - val_accuracy: 0.8158\n",
            "Epoch 247/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8311 - val_loss: 0.4167 - val_accuracy: 0.8158\n",
            "Epoch 248/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8326 - val_loss: 0.4165 - val_accuracy: 0.8158\n",
            "Epoch 249/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8326 - val_loss: 0.4184 - val_accuracy: 0.8158\n",
            "Epoch 250/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8326 - val_loss: 0.4174 - val_accuracy: 0.8158\n",
            "Epoch 251/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8326 - val_loss: 0.4179 - val_accuracy: 0.8158\n",
            "Epoch 252/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8311 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 253/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8311 - val_loss: 0.4156 - val_accuracy: 0.8158\n",
            "Epoch 254/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8311 - val_loss: 0.4153 - val_accuracy: 0.8158\n",
            "Epoch 255/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8326 - val_loss: 0.4169 - val_accuracy: 0.8158\n",
            "Epoch 256/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8326 - val_loss: 0.4161 - val_accuracy: 0.8158\n",
            "Epoch 257/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8326 - val_loss: 0.4149 - val_accuracy: 0.8158\n",
            "Epoch 258/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8311 - val_loss: 0.4149 - val_accuracy: 0.8158\n",
            "Epoch 259/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8326 - val_loss: 0.4174 - val_accuracy: 0.8158\n",
            "Epoch 260/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8326 - val_loss: 0.4172 - val_accuracy: 0.8158\n",
            "Epoch 261/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8326 - val_loss: 0.4168 - val_accuracy: 0.8158\n",
            "Epoch 262/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8326 - val_loss: 0.4176 - val_accuracy: 0.8158\n",
            "Epoch 263/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 264/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8311 - val_loss: 0.4172 - val_accuracy: 0.8158\n",
            "Epoch 265/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8311 - val_loss: 0.4160 - val_accuracy: 0.8158\n",
            "Epoch 266/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8311 - val_loss: 0.4143 - val_accuracy: 0.8158\n",
            "Epoch 267/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8311 - val_loss: 0.4166 - val_accuracy: 0.8158\n",
            "Epoch 268/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4175 - val_accuracy: 0.8158\n",
            "Epoch 269/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8326 - val_loss: 0.4169 - val_accuracy: 0.8158\n",
            "Epoch 270/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8311 - val_loss: 0.4153 - val_accuracy: 0.8158\n",
            "Epoch 271/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8311 - val_loss: 0.4130 - val_accuracy: 0.8158\n",
            "Epoch 272/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4141 - val_accuracy: 0.8158\n",
            "Epoch 273/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8311 - val_loss: 0.4154 - val_accuracy: 0.8158\n",
            "Epoch 274/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8311 - val_loss: 0.4150 - val_accuracy: 0.8158\n",
            "Epoch 275/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4145 - val_accuracy: 0.8158\n",
            "Epoch 276/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4139 - val_accuracy: 0.8158\n",
            "Epoch 277/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4152 - val_accuracy: 0.8158\n",
            "Epoch 278/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8311 - val_loss: 0.4151 - val_accuracy: 0.8158\n",
            "Epoch 279/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8326 - val_loss: 0.4162 - val_accuracy: 0.8158\n",
            "Epoch 280/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8326 - val_loss: 0.4163 - val_accuracy: 0.8158\n",
            "Epoch 281/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8326 - val_loss: 0.4178 - val_accuracy: 0.8158\n",
            "Epoch 282/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8326 - val_loss: 0.4176 - val_accuracy: 0.8158\n",
            "Epoch 283/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8326 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 284/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8326 - val_loss: 0.4172 - val_accuracy: 0.8158\n",
            "Epoch 285/300\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8311 - val_loss: 0.4179 - val_accuracy: 0.8158\n",
            "Epoch 286/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4180 - val_accuracy: 0.8158\n",
            "Epoch 287/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8311 - val_loss: 0.4187 - val_accuracy: 0.8158\n",
            "Epoch 288/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4187 - val_accuracy: 0.8158\n",
            "Epoch 289/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4181 - val_accuracy: 0.8158\n",
            "Epoch 290/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8297 - val_loss: 0.4163 - val_accuracy: 0.8158\n",
            "Epoch 291/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8311 - val_loss: 0.4160 - val_accuracy: 0.8158\n",
            "Epoch 292/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8297 - val_loss: 0.4178 - val_accuracy: 0.8158\n",
            "Epoch 293/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4159 - val_accuracy: 0.8289\n",
            "Epoch 294/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8311 - val_loss: 0.4138 - val_accuracy: 0.8158\n",
            "Epoch 295/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4156 - val_accuracy: 0.8158\n",
            "Epoch 296/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4161 - val_accuracy: 0.8158\n",
            "Epoch 297/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4171 - val_accuracy: 0.8158\n",
            "Epoch 298/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8297 - val_loss: 0.4159 - val_accuracy: 0.8158\n",
            "Epoch 299/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8311 - val_loss: 0.4162 - val_accuracy: 0.8158\n",
            "Epoch 300/300\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8311 - val_loss: 0.4138 - val_accuracy: 0.8158\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=300, validation_data=(X_val, y_val))  # untuk menyimpan nilai metric ke sebuah variable dengan bentuk dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M125xzjiCZIF",
        "outputId": "f8c3611c-541e-4015-ef28-7deda50c4507"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4adb2bd6-0ba1-4b4e-a995-3f3f2761379a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.402725</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>0.416068</td>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.402678</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>0.417132</td>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.402840</td>\n",
              "      <td>0.829662</td>\n",
              "      <td>0.415852</td>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.402675</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>0.416191</td>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.402506</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>0.413778</td>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4adb2bd6-0ba1-4b4e-a995-3f3f2761379a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4adb2bd6-0ba1-4b4e-a995-3f3f2761379a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4adb2bd6-0ba1-4b4e-a995-3f3f2761379a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy\n",
              "295  0.402725  0.831131  0.416068      0.815789\n",
              "296  0.402678  0.831131  0.417132      0.815789\n",
              "297  0.402840  0.829662  0.415852      0.815789\n",
              "298  0.402675  0.831131  0.416191      0.815789\n",
              "299  0.402506  0.831131  0.413778      0.815789"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "metrics = pd.DataFrame(history.history)   # di-convert ke dataframe\n",
        "metrics.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LvZgO240CcwK",
        "outputId": "12e3fa6d-56a2-4991-bc5b-6c97cb2a3334"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics[['loss', 'val_loss']].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCvJmhOeDP13",
        "outputId": "6b26570d-c8c5-4a13-972f-85324fd9242f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(134, 1)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.where(y_pred >= 0.5,1,0)  # untuk mengubah hasil ke 0 atau 1.    Cara baca np.where seperti if pada excel. Jika memenuhi kondisi 0.5, maka diganti jadi 1, kalau tidak maka 0\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIeSdP-2FIB4",
        "outputId": "f8b964da-fb41-44c4-9bc8-a8d799b51da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87        76\n",
            "           1       0.87      0.78      0.82        58\n",
            "\n",
            "    accuracy                           0.85       134\n",
            "   macro avg       0.85      0.84      0.85       134\n",
            "weighted avg       0.85      0.85      0.85       134\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd2gswWPGE09",
        "outputId": "3873497a-8fe2-4048-966b-4fd3f34ac112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to check GPU availability\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANmggOd_ICK3",
        "outputId": "9c4fd567-4494-42a3-f1f4-1ae6a496c67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: nn_titanic/assets\n"
          ]
        }
      ],
      "source": [
        "# save model\n",
        "model.save('nn_titanic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oNz2TXAIGXb"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_titanic = load_model('nn_titanic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI5H2wozIQV-"
      },
      "outputs": [],
      "source": [
        "res_model = model_titanic.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeS3lbKfI4lV",
        "outputId": "bde5fd3c-153c-48eb-e88e-1518b95ce414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_titanic.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlJ0GCiYJMfk"
      },
      "source": [
        "param = jumlah neuron di satu layer dikali jumlah neuron setelahnya\n",
        "\n",
        "32 = neuron di input layer (7 + 1 bias) dikali neuron di hidden layer (4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EV9L6WAn1li"
      },
      "source": [
        "# Modeling with MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LySVbCRJwkl",
        "outputId": "df536fbd-8300-451a-95bd-8ed7ae05caca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 0 - 255    --> scaling pixel. karena max pixel itu 255\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4kKFXfKKUvg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_image(image):\n",
        "  plt.imshow(image, cmap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "tzAT0R0YKdMv",
        "outputId": "38777771-308e-4d28-c55a-d5defa580290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_image(X_train[100])\n",
        "print(y_train[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "471J-PQPKu_E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYlo7HcUK-1T",
        "outputId": "d6f2a18b-ecb8-4c82-dc3b-5349c85d8100"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-zJi5_kLh_V"
      },
      "outputs": [],
      "source": [
        "# siapkan label dengan One Hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_ohe = to_categorical(y_train)\n",
        "y_val_ohe = to_categorical(y_val)\n",
        "y_test_ohe = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HtlDHDRNFQx",
        "outputId": "7064612c-323d-49f7-f342-d5a4f25a89ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(54000, 28, 28)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTWealHPRal_"
      },
      "source": [
        "Ada 54,000 data/gambar/entri dengan ukuran 28x28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvQxAsY3od2o"
      },
      "source": [
        "## Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jghCbXY2L2bW",
        "outputId": "4e340b6f-9610-418b-dfcf-c1093d915b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2669 - accuracy: 0.9214 - val_loss: 0.1406 - val_accuracy: 0.9580\n",
            "Epoch 2/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9611 - val_loss: 0.1016 - val_accuracy: 0.9698\n",
            "Epoch 3/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0853 - accuracy: 0.9733 - val_loss: 0.0805 - val_accuracy: 0.9752\n",
            "Epoch 4/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.0728 - val_accuracy: 0.9798\n",
            "Epoch 5/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9846 - val_loss: 0.0683 - val_accuracy: 0.9793\n",
            "Epoch 6/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
            "Epoch 7/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0805 - val_accuracy: 0.9772\n",
            "Epoch 8/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0718 - val_accuracy: 0.9817\n",
            "Epoch 9/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0723 - val_accuracy: 0.9810\n",
            "Epoch 10/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0811 - val_accuracy: 0.9792\n",
            "Epoch 11/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0743 - val_accuracy: 0.9828\n",
            "Epoch 12/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0869 - val_accuracy: 0.9808\n",
            "Epoch 13/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0862 - val_accuracy: 0.9827\n",
            "Epoch 14/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1225 - val_accuracy: 0.9745\n",
            "Epoch 15/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0945 - val_accuracy: 0.9825\n",
            "Epoch 16/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.0877 - val_accuracy: 0.9828\n",
            "Epoch 17/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1080 - val_accuracy: 0.9798\n",
            "Epoch 18/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.1195 - val_accuracy: 0.9795\n",
            "Epoch 19/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0835 - val_accuracy: 0.9833\n",
            "Epoch 20/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.0959 - val_accuracy: 0.9835\n",
            "Epoch 21/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1186 - val_accuracy: 0.9808\n",
            "Epoch 22/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1068 - val_accuracy: 0.9813\n",
            "Epoch 23/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0902 - val_accuracy: 0.9862\n",
            "Epoch 24/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.1033 - val_accuracy: 0.9845\n",
            "Epoch 25/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1156 - val_accuracy: 0.9823\n",
            "Epoch 26/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1245 - val_accuracy: 0.9837\n",
            "Epoch 27/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1428 - val_accuracy: 0.9815\n",
            "Epoch 28/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1250 - val_accuracy: 0.9822\n",
            "Epoch 29/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1213 - val_accuracy: 0.9837\n",
            "Epoch 30/30\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1202 - val_accuracy: 0.9827\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe33f379110>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# membuat model dengan Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "\n",
        "\"\"\"\n",
        "contoh model sequential dengan arsiterktur yang sama\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\"\"\"\n",
        "\n",
        "# deklarasi arsitektur\n",
        "data_in = Input(shape=(28,28))\n",
        "data_flat = Flatten()(data_in)     # mem-Flatten data yg tadinya 28x28 menjadi 784. ---- 784 dari 28 dikali 28\n",
        "data_drop = Dropout(0.25)(data_flat)\n",
        "hidden_1 = Dense(256, activation='elu')(data_flat)   # yg masuk ke hidden layer 1 adalah data_flat\n",
        "hidden_drop_1 = Dropout(0.25)(hidden_1)\n",
        "hidden_2 = Dense(32, activation='elu')(hidden_1)   # yg masuk ke hidden layer 2 adalah hidden_1\n",
        "hidden_drop_2 = Dropout(0.25)(hidden_2)\n",
        "out = Dense(10, activation='softmax')(hidden_2)    # yg masuk ke outer layer adalah hidden_2\n",
        "\n",
        "model = Model(inputs=data_in, outputs=out)\n",
        "\n",
        "\n",
        "# compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',               # adam adalah optimizer paling modern\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "# train\n",
        "model.fit(X_train, y_train_ohe, epochs=30, validation_data=(X_val, y_val_ohe)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfDOygKOOtZk",
        "outputId": "66814c90-9f2c-49b3-fc62-1c0ba0245790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                8224      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,514\n",
            "Trainable params: 209,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Vry04mDjUq4W",
        "outputId": "d0748183-550f-436b-9f5a-e19d7d044536"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics[['loss','val_loss']].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2LtFnHWyTHKu",
        "outputId": "ce5e19b5-0c11-459e-db79-c9767ddd1398"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_data = X_test[200]\n",
        "\n",
        "show_image(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f7ePiOJTi4H",
        "outputId": "d00bdd6d-271d-4bcf-9279-c908a8a8eaa3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61kjb1emTU8y",
        "outputId": "92c43047-88fb-41e1-dc7c-5bf28500d690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prediksi new data\n",
        "res = model.predict(new_data.reshape(1, 28, 28))   # new data harus di-reshape dahulu menjadi tensor\n",
        "res.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTV5cmbmUJCg",
        "outputId": "24a77122-6fde-4e10-c3a5-459645b064eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.99      0.98      1032\n",
            "           3       0.96      0.98      0.97      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.99      0.98      0.99       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.97      0.96      0.97       974\n",
            "           9       0.97      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFIhCj2dYnz5"
      },
      "source": [
        "# Regression MLP // Regression Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axSz5UfygZjs"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K14MwaNDhrOa"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT1hhtMCgoCX"
      },
      "source": [
        "## Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ashoR4JQgmdr",
        "outputId": "e7de0cea-fc9b-4b1c-c897-a124b6be3609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.7670 - accuracy: 0.0029 - val_loss: 11.2070 - val_accuracy: 0.0044\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6124 - accuracy: 0.0029 - val_loss: 0.4569 - val_accuracy: 0.0044\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4449 - accuracy: 0.0029 - val_loss: 0.4050 - val_accuracy: 0.0044\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4096 - accuracy: 0.0029 - val_loss: 0.4149 - val_accuracy: 0.0044\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4024 - accuracy: 0.0029 - val_loss: 0.3886 - val_accuracy: 0.0044\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.0029 - val_loss: 0.3905 - val_accuracy: 0.0044\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.0029 - val_loss: 0.3910 - val_accuracy: 0.0044\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.0029 - val_loss: 0.3968 - val_accuracy: 0.0044\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.0028 - val_loss: 0.3809 - val_accuracy: 0.0044\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.0028 - val_loss: 0.3934 - val_accuracy: 0.0044\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.0028 - val_loss: 0.3895 - val_accuracy: 0.0044\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.0029 - val_loss: 0.3924 - val_accuracy: 0.0044\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.0029 - val_loss: 0.3942 - val_accuracy: 0.0044\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3681 - accuracy: 0.0028 - val_loss: 0.3871 - val_accuracy: 0.0044\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3701 - accuracy: 0.0028 - val_loss: 0.3675 - val_accuracy: 0.0044\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.0029 - val_loss: 0.3603 - val_accuracy: 0.0044\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3590 - accuracy: 0.0029 - val_loss: 0.4048 - val_accuracy: 0.0044\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.0029 - val_loss: 0.3920 - val_accuracy: 0.0044\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.0029 - val_loss: 0.4098 - val_accuracy: 0.0044\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.0028 - val_loss: 0.3895 - val_accuracy: 0.0044\n"
          ]
        }
      ],
      "source": [
        "# sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "# buat arsitektur\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compile\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer = 'SGD',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# train\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M0H07hwjFmg",
        "outputId": "27eebc0a-4056-4abb-ab55-009498b32b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7cmIU-NgjMxD",
        "outputId": "413d62a3-be07-4725-80a8-1f7dbc498d99"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = pd.DataFrame(history.history)\n",
        "metrics[['loss','val_loss']].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "2urA5ADckQjG",
        "outputId": "a14210f7-9e1b-4b11-fcf0-b75b9ec0be84"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-8c10d1f508b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# untuk mengubah hasil ke 0 atau 1.    Cara baca np.where seperti if pada excel. Jika memenuhi kondisi 0.5, maka diganti jadi 1, kalau tidak maka 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.where(y_pred >= 0.5,1,0)  # untuk mengubah hasil ke 0 atau 1.    Cara baca np.where seperti if pada excel. Jika memenuhi kondisi 0.5, maka diganti jadi 1, kalau tidak maka 0\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwwBPREugIAt"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ANN_with_Keras.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "f7c97302e4b4594ca75996a8da4638e90f26baf6fd49d76b89217181551e7aab"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('streamlit_envi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
